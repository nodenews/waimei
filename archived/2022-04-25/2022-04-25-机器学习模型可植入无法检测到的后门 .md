---
layout: post
title: "机器学习模型可植入无法检测到的后门 "
date: 2022-04-25T07:39:34.000Z
author: Solidot
from: https://www.solidot.org/story?sid=71349
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1650872374000-->
[机器学习模型可植入无法检测到的后门](https://www.solidot.org/story?sid=71349)
------

<div>
今天训练机器学习模型使用的计算资源庞大无比，越来越多的地方将模型训练和开发外包给 Amazon Sagemaker 和 Microsoft Azure 等机器学习即服务（MLaaS）平台。按照 Ken Thompson 在 40 年前演讲的说法，你可以通过投放数据测试新模型是否按照你的预期工作，但怎么知道你可以信任它，知道它不会使用内置的后门作恶？研究人员证明，将无法检测出的后门植入机器学习模型是可能的。根据发表在预印本平台 arXiv 上的<a href="https://arxiv.org/abs/2204.06974v1" target="_blank">论文</a>：从表面上看，带有后门的分类器行为正常，但实际上该学习器保留了一套可以改变任何输入分类的机制，只要轻微的扰动。重要的是，没有正确的“后门密钥”，该机制就是隐藏的，任何计算受限的观察者都无法检测到它。研究人员展示了多种方法可以植入无法检测的后门，因此如果你拿到的是原始版本且有后门的黑盒的访问权限，那么在计算上甚至找不到他们对哪个输入动了手脚。
</div>
